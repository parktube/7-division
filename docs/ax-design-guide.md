# AX (Agent eXperience) 설계 가이드 (시행착오 기반)

> **LLM을 “도구”로만 취급하려는 자연스러운 직관을 넘어, LLM이 능력을 발휘하기 좋은 ‘작업장’을 설계하는 방법**

---

## 이 문서는 누구를 위한가

- **대상**: 엔진/도구/플랫폼을 만드는 **개발자**
- **목적**: “에이전트가 잘 일하는 전문 에디터”를 만들 때, 구현에서 흔히 생기는 마찰을 줄이는 기준을 제공
- **비범위**: 제품 전략/세일즈/브랜딩, UI 디테일(픽셀/모션) 같은 UX 설계

---

## 용어 (1분 정리)

- **AX**: 에이전트가 “추론 → 실행 → 검증”을 끊기지 않게 돕는 설계 기준
- **MCP (Model Context Protocol)**: 도구 호출/컨텍스트 전달을 위한 *프로토콜*
- **Tool**: LLM이 이해하는 스키마 + 실제 실행 구현체(의미론적 인터페이스)
- **ActionHints**: 다음 단계 후보를 응답에 포함해, AI가 목표/상황에 맞게 선택하도록 돕는 힌트
- **MAMA**: “무엇”보다 “왜”를 남기는 추론 그래프(Decision/Checkpoint) 기반 장기 기억

---

## 1. 시행착오: 우리가 자주 두었던 가정들

여기서 말하는 “시행착오”는 누가 틀렸다는 얘기가 아니라,
처음 시스템을 만들 때 **쉽게 선택되는 가정**과 그로 인해 발생하는 **비용/부작용**을 정리한 것이다.

### 시행착오 1: "LLM은 도구다"라고 두고 설계했을 때

```
❌ 흔히 출발하는 관점:
인간 → LLM(도구) → 결과
"LLM을 사용해서 작업을 완료한다"

✅ 우리가 채택한 관점:
인간 ↔ LLM(파트너) ↔ 도구
"LLM과 함께 도구를 사용해서 작업을 완료한다"
```

**증거**: SpineLift 6개월 개발
- 비전문가 + AI = 전문가 혼자 12개월 작업량
- LLM이 "도구"였다면 이 결과는 불가능
- LLM은 **추론하는 파트너**

### 시행착오 2: "정보는 많을수록 좋다"라고 접근했을 때

```
❌ 흔히 생기는 설계:
도구 100개 나열 → LLM이 외워서 사용
튜토리얼 10페이지 → LLM이 읽고 따라함

✅ 우리가 얻은 결론:
도메인 6개 + description → LLM이 추론해서 탐색
힌트 1줄 → LLM이 필요하면 더 찾음
```

**핵심**: LLM은 암기가 아닌 **추론**에 강함

### 시행착오 3: "프로토콜이 필요하다"부터 시작했을 때

```
❌ 현재 SpineLift 아키텍처 (4계층):
Claude → MCP Server → WebSocket → Browser → WASM
        50ms         20ms         20ms      <1ms

총 지연: ~100ms/호출
추가 코드: MCP 서버, WebSocket 핸들러, 브라우저 브릿지

✅ 이상적 아키텍처 (1계층):
Claude → WASM (Node.js)
        <1ms

추가 코드: 도구 스키마 + WASM 로딩/실행(최소)
```

**핵심**: MCP(Model Context Protocol)는 “연결/전달”을 위한 프로토콜. 코어 엔진을 직접 호출할 수 있으면, 프로토콜을 중심에 둘 이유가 줄어든다.

### 시행착오 4: "인간용 UI를 그대로 제공해야 한다"라고 접근했을 때

```
❌ 기존 전문 에디터(인간 중심):
60-70% UI 코드 (메뉴, 단축키, 튜토리얼, 다국어)
30-40% 핵심 엔진

✅ AX-First 전문 에디터:
80-90% 핵심 엔진 (정밀한 API)
10-20% 검증 UI (뷰어, 피드백)

산의 크기: 100x → 40x (60% 감소)
```

### 시행착오 5: "LLM이 부정확해서 사람 중심으로 가야 한다"라고 결론냈을 때

```
❌ 흔히 드는 걱정:
"LLM은 환각(hallucination)을 일으킨다"
"정확한 작업은 인간이 해야 한다"

✅ 우리가 관찰한 트레이드오프:
- 인간: 피로, 실수, 표준 기억 못함
- LLM: 피로 없음, 표준 즉시 조회, 정확한 값 전달

LLM의 약점은 "부정확함"이 아니라 "정밀한 도구가 없었음"
```

---

## 2. 우리가 얻은 5가지 설계 기준 (가드레일)

### 가드레일 1: LLM의 추론을 막지 않는다 (가장 큰 기준)

```
막는 것                          돕는 것
─────────────────────────────────────────────
도구 100개 나열                  도메인 6개 + description
"이 도구를 써라"                 "이런 도메인이 있다"
강제 검색 후 사용                CoT로 자연스럽게 탐색
튜토리얼 10페이지                힌트 1줄
```

**체크 질문**: "이 기능이 LLM의 추론 흐름을 막고 있지는 않은가?"

### 가드레일 2: 협업은 자동화가 아니다

```
자동화                           협업
─────────────────────────────────────────────
LLM이 다 함                      LLM이 하고 → 인간 확인
인간은 결과만 봄                 인간이 피드백
UI 전부 제거                     검증 UI + 최소 개입 UI 유지
```

**체크 질문**: "인간이 결과를 확인하고 피드백할 수 있는가?"

**추가 메모**: 협업에서 인간은 ‘조작자’가 아니라 ‘검증자/결정자’다.  
따라서 인간이 개입할 UI/툴은 없애는 게 아니라 **최소 단위로 설계**한다(예: 승인/거부, 코멘트, 되돌리기, 재실행).

### 가드레일 3: 반복/정밀 작업은 ‘LLM + 정밀 도구’가 강하다

```
인간의 한계                      LLM + 도구의 장점
─────────────────────────────────────────────
피로 → 실수                      피로 없음
표준 기억 못함                   표준 즉시 조회
값 입력 오류                     정확한 값 전달
반복 작업 싫어함                 반복 무한 가능
```

**체크 질문**: "이 작업은 ‘LLM + 도구’가 더 안정적으로 처리할 수 있는가?"

### 가드레일 4: 도구는 LLM의 ‘언어’다 (이름만 봐도 의도가 보이게)

```typescript
// ✅ LLM이 이해하기 쉬움
save_decision(topic, decision, reasoning)
// → "아, 결정을 저장하는 거구나" → CoT 시작

// ❌ LLM에게 인지 부하
INSERT INTO decisions (topic, decision, reasoning) VALUES (...)
// → SQL 파싱 필요 → 추론 방해
```

**체크 질문**: "도구 이름만 보고 LLM이 의도를 이해할 수 있는가?"

### 가드레일 5: 블랙박스를 만들지 않는다 (진행상황은 투명해야 한다)

협업에서는 “결과물”만이 아니라 “지금 무엇을 했고, 왜 그렇게 했고, 다음에 무엇을 할지”가 보여야 한다.
AI가 잘못된 방향으로 가는 것을 가장 빨리 잡아내는 건 인간의 검증이기 때문에, 상태가 불투명하면 협업이 무너진다.

**체크 질문**
- "지금 상태를 인간이 한눈에 이해하고 개입할 수 있는가?"
- "실행의 근거/로그/산출물이 남아 재현 가능한가?"

---

## 3. 개발자 최소 스펙 (권장 기본값)

가드레일은 방향이고, 개발자는 “무엇을 구현해야 하는가”가 필요하다. 아래는 최소 스펙(기본값)이다.

### 3.1 상태/이벤트 모델 (진행상황 투명성의 최소 단위)

- **Run(작업 실행) ID**: 모든 자동 실행은 `runId`로 식별되고 재현 가능해야 한다.
- **상태**: `queued` → `running` → `succeeded|failed|canceled`
- **Step(단계)**: run은 단계 목록을 가진다. 각 step도 동일한 상태 + `startedAt/endedAt`를 가진다.
- **Progress**: `progress(0..1)` 또는 `currentStepIndex/totalSteps` 중 하나는 항상 노출한다.
- **이벤트 스트림**(실시간/리플레이 가능): `run_started`, `step_started`, `step_progress`, `log`, `artifact_created`, `needs_approval`, `approved|rejected`, `step_completed`, `run_completed`

### 3.2 최소 개입 UI (인간이 “결정”할 수 있는 단위)

사람은 “조작”이 아니라 “결정/피드백”을 해야 한다.

- `approve/reject`: 다음 step 또는 현재 plan 전체에 대한 승인/거부
- `comment/request_change`: 수정 요청(텍스트 피드백) + 재실행 트리거
- `pause/cancel`: 안전하게 중단(중간 산출물 보존)
- `undo/rollback`: 최소 단위(직전 step / 체크포인트)로 되돌리기
- `rerun`: step 단위 또는 run 단위 재실행(동일 입력으로 재현 가능)

### 3.3 투명성 출력 포맷 (요약 + 드릴다운)

기본 화면/로그는 “짧고 구조적”이어야 한다. 자세한 내용은 드릴다운으로 제공한다.

- **요약(항상 노출)**: `Goal`, `Current`, `Next`, `Artifacts`, `Risks/Unknowns`
- **근거(항상 링크)**: 로그/디프/이미지/JSON 등 산출물은 경로/ID로 추적 가능해야 한다.
- **드릴다운**: step별 입력/출력/실행 로그/에러/재현 방법

### 3.4 승인 게이트(기본 정책)

자동화가 강해질수록 “언제 인간 승인이 필요한가”를 기본값으로 정해야 한다.

- **기본값**: 읽기/분석/시뮬레이션/미리보기는 자동, **파괴적/비가역/외부영향**은 승인
- **승인 필요 예시**
  - 삭제/덮어쓰기/대량 변경(프로젝트 파일, 에셋, 상태)
  - 비용/시간이 크게 드는 실행(대규모 배치, 장시간 작업)
  - 네트워크/외부 API 호출, 권한 상승, 배포/공유 같은 외부 영향
- **게이트의 투명성**: 왜 막혔는지(근거) + 승인 시 무엇이 실행되는지(예상 변경/비용/리스크)를 반드시 보여준다.

---

## 4. 불필요한 장벽 체크리스트

### 아키텍처 장벽

| 장벽 | 문제 | 해결 |
|------|------|------|
| MCP 프로토콜 | 4계층 → 지연, 복잡도 | Tool 직접 등록 |
| WebSocket | 브라우저 의존성 | Node.js WASM |
| 브라우저 필수 | 협업/검증이 멈춤 | **실시간 검증 UI(브라우저)는 유지**, 조작/계산은 direct/batch |
| 실시간 동기화 | 상태 동기화 비용 | 실시간은 **검증/피드백 루프**에 한정, 엔진을 단일 소스로 유지 |

### 인터페이스 장벽

| 장벽 | 문제 | 해결 |
|------|------|------|
| 도구 100개 나열 | 외워야 함 | 도메인 6개 + 추론 |
| 긴 description | 컨텍스트 낭비 | 1줄 요약 + 힌트 |
| 로컬/월드 좌표 혼란 | 추가 변환 필요 | 월드 좌표 통일 |
| 복잡한 파라미터 | 오용 위험 | 추상화 (intensity: 0.3) |

### 워크플로우 장벽

| 장벽 | 문제 | 해결 |
|------|------|------|
| 단계별 확인 강제 | 피로 | 배치 후 최종 확인 |
| 모든 정보 선제공 | 컨텍스트 낭비 | Just-in-Time 주입 |
| 강제 검색 | 추론 방해 | 힌트로 유도 |
| 에러 시 중단 | 흐름 끊김 | ActionHints로 대안 제시 |

---

## 5. 바로 쓰는 레시피 (AX 설계 패턴)

### 패턴 1: Progressive Knowledge Exposure (점진적 지식 노출)

```
❌ 한번에 모든 정보
project tool (10개 action 설명)
mesh tool (15개 action 설명)
skeleton tool (20개 action 설명)
... (최적화 이전) 100개 action = 43k 토큰

✅ 점진적 노출
project: "프로젝트 관리"
mesh: "메쉬 생성"
skeleton: "본 편집"
→ LLM이 필요할 때 탐색
→ 5k 토큰으로 시작
```

### 패턴 2: ActionHints (다음 행동 제안)

```typescript
// Tool 응답에 포함
{
  result: { bones: [...] },
  actionHints: {
    recommended: [
      { action: "generate_weights", reason: "본 생성 완료, 웨이트 필요" },
      { action: "get_hull_visualization", reason: "시각적 확인 권장" }
    ]
  }
}
```

LLM은 **수용/거부/변형** 최종 판단만. 추론능력 그대로 활용.

### 패턴 3: Just-in-Time Knowledge Injection

```
3계층 지식 구조:
─────────────────────────────────────────
Level 1: Domain Rules (불변)
         - Spine 본 규칙, PCB clearance

Level 2: Product Specifics (프로젝트별)
         - 특정 캐릭터 구조

Level 3: Session History (MAMA)
         - 과거 성공/실패 패턴
```

필요할 때만 주입. 미리 다 주지 않음.

### 패턴 4: Tool as Language

```typescript
// ✅ 좋은 도구 이름 (의미가 명확)
create_bone
generate_weights
export_to_spine_json

// ❌ 나쁜 도구 이름 (의미 불명확)
process
execute
run
```

### 패턴 5: LLM-Native 추상화 (OOP가 아님!)

복잡한 시스템에서 추상화가 필요할 때, OOP(캡슐화/상속)보다 LLM 친화적 패턴을 선택한다.

```
❌ OOP 캡슐화 = 블랙박스 = LLM에 불리
house.setWallColor(red)  // wall이 뭐지? 내부 상태는?

✅ LLM-Native = 명시적 범위 + 탐색 가능
enterScope("house_1");
setFill("wall", red);     // 현재 스코프 내 명시적 타겟
exitScope();
```

**LLM-Native 추상화 4요소:**

| 요소 | 설명 | 예시 |
|------|------|------|
| **Scoped Context** | 작업 범위 제한 | `enterScope("room_12")` → 상대 경로 사용 |
| **Query Language** | 조건 검색 | `find({ type: "chair", in: "room_*" })` |
| **Progressive Disclosure** | 점진적 탐색 | `overview()` → `listChildren()` → drill-down |
| **Batch Operations** | 일괄 처리 | `batch([{ target: "chair_*", op: "setFill" }])` |

**규모별 적용:**

```
~500 엔티티:   플랫 + 네이밍 컨벤션
~5,000 엔티티: Scoped Context + Progressive Disclosure
~50,000 엔티티: Query + Batch Operations
무제한:        LOD + Lazy Loading
```

**핵심 원칙**:
- OOP의 "숨기기"가 아닌 "범위 제한"
- 상속 계층이 아닌 "탐색 가능한 구조"
- 암시적 상태가 아닌 "명시적 컨텍스트"

---

## 6. 설계 시 자문 체크리스트

프로그램 설계 전 스스로에게 묻기:

### 추론 관점
- [ ] 이 기능이 LLM의 추론을 막고 있지는 않은가?
- [ ] 외우게 하는 대신 추론하게 하고 있는가?
- [ ] 강제하는 대신 유도하고 있는가?

### 아키텍처 관점
- [ ] 이 계층이 정말 필요한가?
- [ ] 코어 조작/계산 경로가 프로토콜 없이 직접 호출 가능한가? (Direct-first)
- [ ] 코어 조작/계산 경로가 브라우저 없이 동작 가능한가?

### 협업 관점
- [ ] 인간이 결과를 확인할 수 있는가?
- [ ] 피드백 루프가 존재하는가?
- [ ] 조작 UI인가, 검증 UI인가?
- [ ] 최소 개입 UI가 있는가? (approve/reject, annotate, undo/rollback, rerun)
- [ ] 실시간 검증 뷰어가 있는가? (협업 시)
- [ ] 진행상황이 투명한가? (현재 단계/근거/로그/산출물/다음 행동)

### 도구 관점
- [ ] 도구 이름만 보고 의도를 이해할 수 있는가?
- [ ] 힌트가 다음 행동을 안내하는가?
- [ ] 도메인 지식이 필요할 때 주입되는가?

---

## 7. 사례: SpineLift에서 실제로 치른 비용들

### 비용 1: MCP 4계층 아키텍처
```
Claude → MCP → WebSocket → Browser → WASM

문제: 100ms 지연, 코드 복잡도, 브라우저 의존성
원인: "MCP가 표준이니까" → 전제/비용을 충분히 분해하지 못함
교훈: 표준이라고 무조건 따르지 말고, 필요성을 질문하라
```

### 비용 2: (당시) description 컨텍스트 폭증
```
(최적화/정리 이전) animation 도구 description이 12.6k 토큰(330줄) 수준까지 커졌던 적이 있음

문제: 컨텍스트 22% 점유, LLM 주의 분산
원인: "자세히 설명해야 LLM이 이해한다"라는 가정 → 과잉 설명으로 이어짐
교훈: 간결할수록 LLM이 추론하기 좋다
```

### 비용 3: 로컬/월드 좌표 혼란
```
create_bone(x, y, parentId)
→ description: "월드 좌표"
→ 실제: 로컬 좌표로 처리

문제: 본이 의도한 위치에 안 생김
원인: WASM과 MCP 인터페이스 불일치
교훈: 추상화 레벨을 일관되게 유지하라
```

### 비용 4: 브라우저 필수 의존성
```
WASM이 “브라우저에 묶여 있다”고 가정

문제: 브라우저가 꺼지면 협업(실시간 검증/피드백)이 멈춤
원인: "렌더링 = 브라우저" → 고정관념
교훈: **계산/조작 경로는 브라우저와 분리**하되, 협업을 위한 **실시간 검증 UI는 유지**하라
```

---

## 8. 목표 아키텍처 (방향)

```
현재 (복잡)                      이상 (단순)
─────────────────────────────────────────────
Claude                           Claude
   ↓                                ↓
MCP Server                       Tool (직접)
   ↓                                ↓
WebSocket                        WASM (Node.js)
   ↓                                ↓
Browser                          협업/검증(실시간)
   ↓                                ↓
WASM                             Browser Viewer
   ↓
Canvas 렌더링

4계층, 100ms                     1계층, <1ms
항상 브라우저 필요               협업 시 브라우저(실시간)
```

### 아키텍처 요점

- **Direct-first**: 코어 엔진은 직접 호출이 기본(지연/상태/복잡도 최소화)
- **MCP는 가장자리(어댑터)**: 외부 호스트/원격/브라우저 상태 접근 등 “경계 문제”를 다룰 때만 사용
- **협업은 실시간 검증 UI가 필요**: 브라우저(또는 동급의 라이브 뷰어)는 인간 피드백을 위해 상시 유지
- **MAMA는 메모리 계층**: 에이전트 런타임에서 직접 호출이 기본, 필요하면 MCP 어댑터로도 노출

### 구현 경로
1. WASM을 Node.js에서 로드 (Emscripten 지원)  
   - 전제: WASM 빌드가 Node 환경을 타겟으로 포함해야 함 (현재는 web/worker 중심)
2. Claude 도구로 직접 등록
3. 협업용 브라우저 뷰어(실시간) 유지 + Headless 렌더러는 자동화/비동기 검증 보조
4. MAMA는 LLM 메모리, 브라우저 뷰어는 인간 검증/피드백 루프

---

## 9. 자주 나오는 질문: "LLM이 더 똑똑해지면 AX가 덜 중요해지지 않나?"

AI 업계는 스케일링 법칙을 이야기한다. LLM이 더 똑똑해지면 나쁜 인터페이스도 알아서 해석하고, 힌트 없이도 추론하고, 4계층 MCP도 문제없이 처리할 것이라고.

**하지만 우리의 경험상, 그렇게 단순하지 않았다.**

### 아인슈타인 비유

```
아인슈타인이 더 똑똑해지면:
- 종이와 펜이 불필요해지는가?
- 연구실이 불필요해지는가?
- 동료 검증이 불필요해지는가?

아니다.

더 좋은 환경에서 더 많은 것을 할 수 있을 뿐이다.
```

### 지능과 환경의 관계

```
지능 × 환경 = 결과

지능이 높아져도 환경이 0이면 결과는 0.
지능과 환경은 대체 관계가 아니라 승수 관계다.
```

| 조합 | 지능 | 환경 | 결과 |
|------|------|------|------|
| 인간 + 나쁜 도구 | 1.0 | 0.5 | 0.5 |
| 인간 + 좋은 도구 | 1.0 | 1.0 | 1.0 |
| GPT-4 + 나쁜 도구 | 2.0 | 0.5 | 1.0 |
| GPT-4 + 좋은 도구 | 2.0 | 1.0 | 2.0 |
| GPT-5 + 나쁜 도구 | 4.0 | 0.5 | 2.0 |
| GPT-5 + 좋은 도구 | 4.0 | 1.0 | **4.0** |

**LLM이 똑똑해질수록 좋은 환경과 나쁜 환경의 격차가 벌어진다.**

### 스케일링으로 바뀌는 것 vs 바뀌지 않는 것

| 불필요해질 수 있는 것 | 여전히 필수인 것 |
|---------------------|-----------------|
| ActionHints (스스로 추론) | 가드레일 1: 추론 막지 않기 |
| Progressive Exposure | 협업 (검증 UI) |
| 추상화 파라미터 | 불필요한 계층 제거 |
| description 최적화 | 도구 = 언어 (시맨틱 명확성) |

### 자원은 항상 유한하다

```
초지능도:
- 컨텍스트 한계가 있음 (물리적)
- 추론 시간이 있음 (비용)
- 전력을 소모함 (환경)

4계층 → 1계층은 "똑똑해지면 해결"이 아니라
효율성의 문제. 낭비는 낭비.
```

### 협업의 본질은 변하지 않는다

```
LLM이 아무리 똑똑해져도:
1. 인간의 목표를 대신 정할 수 없음
2. 인간의 만족을 대신 판단할 수 없음
3. 피드백 없이 협업은 불가능

검증 UI는 스케일링과 무관하게 필수.
```

### 결론

```
AX의 본질:
"LLM의 한계를 보완"이 아니라
"LLM의 능력이 발휘될 공간 제공"

이 본질은 스케일링과 무관하다.

스케일링 법칙이 맞다면,
AX는 더 불필요해지는 게 아니라
더 중요해진다.
```

---

## 10. 한 문장 요약

> **"LLM에게 도구를 쥐어주는 게 아니라, LLM이 추론할 수 있는 장소를 제공하라."**

---

## 11. 관련 디시전

- `spinelift:ax_master_principles` - AX 설계 기준 v2 (가드레일)
- `spinelift:ax_design_principle` - 추론능력을 막지 않는다
- `spinelift:ax_implementation_architecture` - 구현 3계층
- `spinelift:ax_progressive_exposure` - 점진적 지식 노출
- `spinelift:mcp_vs_direct_wasm` - MCP vs 직접 호출
- `mcp_tool_description_optimization` - description 최적화
- `cad:llm_native_abstraction` - LLM-Native 추상화 (OOP가 아닌 대안)
- `cad:phase4_llm_friendly_navigation` - LLM 친화적 씬 탐색

---

*최종 수정: 2026-01-03*
*출처: SpineLift 6개월 개발 경험 + MAMA 프로젝트 + AI-Native CAD(도화지)*
